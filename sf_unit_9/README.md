# Car Price prediction Part 2
## Описание:
Продолжение соревнования на Прогнозирование стоимости автомобиля но уже с дополнительными данными.
Вам поставлена задача создать модель, которая будет предсказывать стоимость автомобиля.
Если наша модель работает хорошо, то мы сможем быстро выявлять выгодные предложения (когда желаемая цена продавца ниже предсказанной рыночной цены). Это значительно ускорит работу менеджеров и повысит прибыль компании.  

### Чем мы будем заниматься?

* Построим "наивную"/baseline модель, предсказывающую цену по модели и году выпуска (с ней будем сравнивать другие модели)
* Обработаем и отнормируем признаки
* Сделаем первую модель на основе градиентного бустинга с помощью CatBoost
* Сделаем вторую модель на основе нейронных сетей и сравним результаты
* Сделаем multi-input нейронную сеть для анализа табличных данных и текста одновременно
* Добавим в multi-input сеть обработку изображений
* Осуществим проброс признака 
* Осуществим ансамблирование градиентного бустинга и нейронной сети (усреднение их предсказаний)  

### Условия соревнования:  
[Ссылка на закрытое соревнование](https://www.kaggle.com/competitions/sf-dst-car-price-prediction-part2)  
- Данное соревнование является бессрочным и доступно для всех потоков.
- Срок выполнения соревнования устанавливаеться индивидуально в каждом потоке.
- Тестовая выборка представлена в ЛидерБорде целиком.
- Разрешено использовать любые ML и DL алгоритмы и библиотеки.
- Лучшие и победные решения буду проверяться на воспроизводимость и "адекватность" (чтоб не было подгонки под тестовую выборку).

**Метрика качества**  
Результаты оцениваются по метрике mape — средняя абсолютная процентная ошибка

### Краткая информация о данных
- train.csv - the training set  
- test.csv - the test set
- img.zip - image auto
- sample_submission.csv - a sample submission file in the correct format  

## Этапы работы над проектом  
- провел 20+ тестов и сформировал предварительные гиперпараметры модели перед тонкой настройкой  
- протестировал различные архитектуры головы (Custom Head)  
- протестировал несколько методов аугментации данных  
    - встроенный в keras класс ImageDataGenerator  
    - библиотека для аугментации данных albumentations  
- Собрал из внешних источников 4468 изображений авто из представленных классов для:  
    - устранения не сбалансированности классов  
    - повышения качества модели за счет обучения на большем кол-ве данных
- В ручном режиме отфильтровал из тренировочных данных изображения, не соответствующие представленным классам
- протестировал несколько основных callback-функций с разными параметрами:  
    - ModelCheckpoint  
    - EarlyStopping  
    - EarlyStopping  
    - ReduceLROnPlateau  
- обучение, протестировал разные вариации LR и sheduler  
- применил тонкую настройку модели (fine-tuning):
    - Этап 1: заморозил базовую модель полностью
    - Этап 2: заморозил базовую модель на половину и снизил LR и BATCH_SIZE
    - Этап 3: разморозил базовую модель полностью и снизил LR и BATCH_SIZE
    - Этап 4: Увеличил размер входных данных и понизил уровень аугментации данных, а так же BATCH_SIZE
- сделал сабмишн на чистых тестовых данных
- сделал сабмишн на тестовых данных с использованием TTA

## Результат:  
- score на kaggle = 0.97138 (73 место из 264)  
- [ноутбук на kaggle](https://www.kaggle.com/alekseykonotop/final-notebook-ar-lassification-ipynb)  
- score без TTA - 0.97138  
- score c TTA - 0.92344 - значительно хуже