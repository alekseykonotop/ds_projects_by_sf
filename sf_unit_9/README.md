# Car Price prediction Part 2
## Описание:
Продолжение соревнования на Прогнозирование стоимости автомобиля но уже с дополнительными данными.
Вам поставлена задача создать модель, которая будет предсказывать стоимость автомобиля.
Если наша модель работает хорошо, то мы сможем быстро выявлять выгодные предложения (когда желаемая цена продавца ниже предсказанной рыночной цены). Это значительно ускорит работу менеджеров и повысит прибыль компании.  

### Чем мы будем заниматься?

* Построим "наивную"/baseline модель, предсказывающую цену по модели и году выпуска (с ней будем сравнивать другие модели)
* Обработаем и отнормируем признаки
* Сделаем первую модель на основе градиентного бустинга с помощью CatBoost
* Сделаем вторую модель на основе нейронных сетей и сравним результаты
* Сделаем multi-input нейронную сеть для анализа табличных данных и текста одновременно
* Добавим в multi-input сеть обработку изображений
* Осуществим проброс признака 
* Осуществим ансамблирование градиентного бустинга и нейронной сети (усреднение их предсказаний)  

### Условия соревнования:  
[Ссылка на закрытое соревнование](https://www.kaggle.com/competitions/sf-dst-car-price-prediction-part2)  
- Данное соревнование является бессрочным и доступно для всех потоков.
- Срок выполнения соревнования устанавливаеться индивидуально в каждом потоке.
- Тестовая выборка представлена в ЛидерБорде целиком.
- Разрешено использовать любые ML и DL алгоритмы и библиотеки.
- Лучшие и победные решения буду проверяться на воспроизводимость и "адекватность" (чтоб не было подгонки под тестовую выборку).

**Метрика качества**  
Результаты оцениваются по метрике mape — средняя абсолютная процентная ошибка

### Краткая информация о данных
- train.csv - the training set  
- test.csv - the test set
- img.zip - image auto
- sample_submission.csv - a sample submission file in the correct format  

## Выводы по проекту 
В рамках проекта выполнил:  
- предобработка данных  
- разведывательный анализ - дал понимание с какими данными мы работаем, а так же выводы по удалению некоторыз признаков, которые либо имели большое кол-во пропусков данных, либо только 1 значение, или высокую корреляцию между собой. Созданы новые признаки.  
- обработки естественного языка  
  - токенизация и лематизация данных - Однако, считаю, что текстовые данные можно было обработать лучше. Ограниченность по времени не позволила это сделать.  
- аугментация данных с помощью библиотеки albumentation.  
- провел более 20+ тестов при подборе гиперпараметров моделей моделей

В рамках проекта удалось попрактиковаться с:  
- работой с multi-input моделями  
- оркестрация моделей  
- проброс признака  
- блендинг предсказаний, который позволил получить score 11.36165 на лидерборде.

## Результат:  
- score на kaggle = 11.36165 (62 место из 183)  
- [ноутбук на kaggle](https://www.kaggle.com/code/alekseykonotop/sf-dst-car-price-part-2)