{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скрипт для соединения двух датасетов, скачанных с auto.ru в разное время.\n",
    "Если вы планируете использовать скрипт в своих целях, как инструмент для конкатенации нескольких датасетов, полученных после запуска парсера  auto_ru_parser, то вам стоит пропустить этап \"Удаление не корректных данных по ПТС\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "DIR_DATA = 'parsing_data/'\n",
    "DIR_TEST = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_1: (162913, 35)\n",
      "df_2: (56457, 36)\n"
     ]
    }
   ],
   "source": [
    "df_1 = pd.read_csv(DIR_DATA + 'cars_prices_multiprocessing.csv')\n",
    "df_2 = pd.read_csv(DIR_DATA + 'cars_prices_multiprocessing_08_11_2020.csv')\n",
    "\n",
    "print(f\"df_1: {df_1.shape}\")\n",
    "print(f\"df_2: {df_2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New size df_1: (161714, 35)\n",
      "New size df_1: (55508, 36)\n"
     ]
    }
   ],
   "source": [
    "# В данные попадает аж 187 раз заголовки для csv-таблицы. Удалим их\n",
    "df_1 = df_1.loc[df_1.brand != 'brand']\n",
    "print(f\"New size df_1: {df_1.shape}\")\n",
    "\n",
    "df_2 = df_2.loc[df_2.brand != 'brand']\n",
    "print(f\"New size df_1: {df_2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape df_1 without duplicates: (55541,)\n",
      "Shape df_2 without duplicates: (54043,)\n"
     ]
    }
   ],
   "source": [
    "# Проверим наличие дубликатов по sell_id\n",
    "print(f\"Shape df_1 without duplicates: {df_1.sell_id.unique().shape}\")\n",
    "print(f\"Shape df_2 without duplicates: {df_2.sell_id.unique().shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первом датасете действительно содержится много дубликатов. Это результат моей не внимательности.  \n",
    "Запускал скрипт пасринга несколько раз без очистки csv-файла, в который выполнялась записи данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New size: (55884, 35)\n",
      "New size: (54256, 36)\n"
     ]
    }
   ],
   "source": [
    "# Удалим дубли по признаку sell_id\n",
    "df_1.drop_duplicates(subset=['sell_id'], keep='last', inplace=True)\n",
    "print(f\"New size: {df_1.shape}\")\n",
    "\n",
    "df_2.drop_duplicates(subset=['sell_id'], keep='last', inplace=True)\n",
    "print(f\"New size: {df_2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Первичная обработка данных\n",
    "\n",
    "При парсинге первого датасета df_1 мной была допущена ошибка при получении значения ПТC.  \n",
    "Она привела к тому, что значения Дубликат нет совсем, вместо него записано значение Оригинал.  \n",
    "Но мне повезло, что есть второй датасет, собранный немного позже. Второй датасет в большей части дублируем информацию из первого.  \n",
    "Так же в тестовом датасете могут содержаться теже записи, которые есть в первом датасета.  \n",
    "\n",
    "Конечно не хочется терять данные, но значение признака price, сильно меняется от значения признака ПТС.  \n",
    "Поэтому лучше потерять часть данных, но восстановить информативность сотавшихся.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyType                    2\n",
       "brand                       0\n",
       "color_hex                   0\n",
       "description              1639\n",
       "engineDisplacement          2\n",
       "enginePower                 2\n",
       "equipment_dict          12339\n",
       "fuelType                    2\n",
       "image                       0\n",
       "mileage                     0\n",
       "modelDate                   2\n",
       "model_info                  0\n",
       "model_name                  0\n",
       "name                        2\n",
       "numberOfDoors               2\n",
       "parsing_unixtime            0\n",
       "priceCurrency             211\n",
       "productionDate              0\n",
       "sell_id                     0\n",
       "section                     0\n",
       "url_saleid                  0\n",
       "super_gen                   2\n",
       "vehicleConfiguration        2\n",
       "vehicleTransmission         2\n",
       "vendor                      0\n",
       "Владельцы               12799\n",
       "ПТС                       333\n",
       "Привод                      2\n",
       "Руль                        0\n",
       "Состояние                 886\n",
       "Таможня                     0\n",
       "price                     211\n",
       "price_timestamp           211\n",
       "auto_class                299\n",
       "price_segment               2\n",
       "seller_type                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим объекты с пропусками в след. признаках, а так же где нет цены, так как кол-во пропусков там минимально\n",
    "cols_to_dropna = 'bodyType engineDisplacement enginePower fuelType modelDate name numberOfDoors super_gen vehicleConfiguration vehicleTransmission Привод price price_timestamp price_segment'.split(' ')\n",
    "\n",
    "\n",
    "df_1 = df_1.dropna(subset=cols_to_dropna)\n",
    "df_2 = df_2.dropna(subset=cols_to_dropna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# переведем признаки price и sell_id в формат int64\n",
    "df_1.price = df_1.price.astype('int64')\n",
    "df_1.sell_id = df_1.sell_id.astype('int64')\n",
    "\n",
    "df_2.price = df_2.price.astype('int64')\n",
    "df_2.sell_id = df_2.sell_id.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ПТС</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DUPLICATE</th>\n",
       "      <td>606521</td>\n",
       "      <td>420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORIGINAL</th>\n",
       "      <td>2091804</td>\n",
       "      <td>1050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean   median\n",
       "             price    price\n",
       "ПТС                        \n",
       "DUPLICATE   606521   420000\n",
       "ORIGINAL   2091804  1050000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим влияет ли признак ПТС на таргет\n",
    "pd.pivot_table(df_2, values=['price'], index=['ПТС'],\n",
    "               aggfunc=[np.mean, np.median]).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из сводной таблицы, по среднему разница более чем в 3 раза, по медиане разница более чем в 2.5 раза.  \n",
    "Это подтверждает мое решение пожертвовать частью данных, где этот признак получен с не верным значением."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаление не корректных данных по  ПТС"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем тестовые данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34686, 32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(DIR_TEST+'test_26_10_2020.csv')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В тесте есть: 3661 записей содержащиъся в df_1\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Посмотрим какое кол-во объявлений из трейна есть в тесте.  Это нужно для того, чтобы постараться по максимуму свосстановить корректные значения признака ПТС в трейне из теста по признаку sel_id\n",
    "\n",
    "train_1_ids = df_1.sell_id.unique()\n",
    "train_2_ids = df_2.sell_id.unique()\n",
    "test_ids = test.sell_id.unique()\n",
    "\n",
    "diff_train_1_train_2_ids = set(train_1_ids) - set(train_2_ids)\n",
    "common_tr_1_tr_2_and_test_ids = set(diff_train_1_train_2_ids) & set(test_ids)\n",
    "\n",
    "print(f\"В тесте есть: {len(common_tr_1_tr_2_and_test_ids)} записей содержащиъся в df_1\")\n",
    "\n",
    "# Сокращаем df_1 до тех записей, которые есть в common_tr_1_tr_2_and_test_ids\n",
    "df_1 = df_1[df_1.sell_id.isin(common_tr_1_tr_2_and_test_ids)]\n",
    "df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь пройдемся по каждой строке df_1 и заменим значение признака ПТС из теста\n",
    "def fill_pts_value_from_test(row):\n",
    "    curr_sell_id = row['sell_id']\n",
    "    \n",
    "    if curr_sell_id in test_ids:\n",
    "        pts_in_test = test[test.sell_id == curr_sell_id].ПТС.iloc[0]\n",
    "        row['ПТС'] = pts_in_test\n",
    "    \n",
    "    return row\n",
    "\n",
    "df_1 = df_1.apply(fill_pts_value_from_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Оригинал    3240\n",
       "Дубликат     421\n",
       "Name: ПТС, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим результат\n",
    "df_1.ПТС.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объединение df_1 и df_2\n",
    "В процессе отладки парсера, были приняты решения от некоторых признаков отказаться и добавить другие.  \n",
    "Ввиду этого размерность df_1 и df_2 не совпадают.  \n",
    "Удалим не нужные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для df_1\n",
    "cols_to_del_df_1 = ['model', 'price_timestamp']\n",
    "df_1.drop(labels=cols_to_del_df_1, axis=1, inplace=True)\n",
    "\n",
    "# для df_2\n",
    "cols_to_del_df_2 = ['price_timestamp']\n",
    "df_2.drop(labels=cols_to_del_df_2, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на типы данных в обоих датасетах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для поиска различий типов данных\n",
    "def find_data_type_discrepancy(data_1, data_2):\n",
    "    \"\"\"\n",
    "    Функция ищет различия в типах данных \n",
    "    между датасетами и выводит информацию на экран.\n",
    "    Ничего не возвращает\n",
    "    :param train: DataFrame object with training data\n",
    "    :param test: DataFrame object with testing data\n",
    "    \"\"\"\n",
    "    \n",
    "    data_1_dtypes_df = data_1.dtypes.reset_index()\n",
    "    data_1_dtypes_df.columns = 'col_name type_data_1'.split(' ')\n",
    "\n",
    "\n",
    "    data_2_dtypes_df = data_2.dtypes.reset_index()\n",
    "    data_2_dtypes_df.columns = 'col_name type_data_2'.split(' ')\n",
    "\n",
    "\n",
    "    merged_df = data_1_dtypes_df.merge(data_2_dtypes_df, how='outer',\n",
    "                                       left_on='col_name', right_on='col_name')\n",
    "    merged_df\n",
    "\n",
    "    print(f\"{'Расхождение типов данных:'}\")\n",
    "    print(f\"{'Признак'.ljust(21)} | {'data_1'.ljust(15)} | {'data_2'.ljust(15)}\")\n",
    "    print('-'*48)\n",
    "\n",
    "    for index, row in merged_df.iterrows():\n",
    "        if str(row['type_data_1']) == 'nan' or str(row['type_data_2']) == 'nan':\n",
    "            print(f\"{str(row['col_name']).ljust(21)} | {str(row['type_data_1']).ljust(15)} | {str(row['type_data_2']).ljust(15)}\")\n",
    "\n",
    "        elif row['type_data_1'] != row['type_data_2']:\n",
    "            print(f\"{str(row['col_name']).ljust(21)} | {str(row['type_data_1']).ljust(15)} | {str(row['type_data_2']).ljust(15)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расхождение типов данных:\n",
      "Признак               | data_1          | data_2         \n",
      "------------------------------------------------\n",
      "section               | nan             | object         \n",
      "url_saleid            | nan             | object         \n"
     ]
    }
   ],
   "source": [
    "find_data_type_discrepancy(df_1, df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, различий нет, можно конкатенировать датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57704, 35)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_1.append(df_2, sort=False).reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запись в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(data):\n",
    "    date_str = datetime.now().strftime('%d_%m_%Y')\n",
    "    df.to_csv(f\"concatenated_dataset_{date_str}.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to csv-file\n",
    "write_to_csv(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом конкатенация двух датасетов и исправление данных в признаке ПТС завершена.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
